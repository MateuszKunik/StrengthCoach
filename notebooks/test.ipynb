{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['timestamp'] + [name.lower() + '_' + char for name in landmark_names for char in ('x', 'y', 'z')]\n",
    "\n",
    "data = pd.DataFrame(columns = column_names, dtype = float)\n",
    "\n",
    "time = 0\n",
    "cap = cv2.VideoCapture(source)\n",
    "\n",
    "# Setup MediaPipe instance\n",
    "with mp_pose.Pose(\n",
    "    min_detection_confidence=0.75,\n",
    "    min_tracking_confidence=0.75,\n",
    "    enable_segmentation=True\n",
    ") as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "        image_shape = image.shape\n",
    "\n",
    "\n",
    "        # Camera condition -> if selfie or web camera is chosen then flip image\n",
    "        if source == 0:\n",
    "            image = cv2.flip(image, 1)\n",
    "    \n",
    "        # Recolor image for image processing\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Image MediaPipe processing -> detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor back to BGR for visualization\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # create a fake background\n",
    "        fake_background = np.zeros(shape=image_shape, dtype='uint8')\n",
    "        # use a fake background if necessary\n",
    "        if not background:\n",
    "            image = fake_background\n",
    "\n",
    "        # Image processing for different outputs\n",
    "        if output == 'landmarks':\n",
    "            default_landmarks = results.pose_landmarks\n",
    "\n",
    "            if default_landmarks:\n",
    "                time += 1\n",
    "\n",
    "                # Get custom landmarks and create new connection\n",
    "                custom_landmarks = get_custom_landmarks(chosen_indexes, default_landmarks)\n",
    "                #custom_connections.add((0, len(custom_landmarks.landmark) - 1))\n",
    "\n",
    "                # Prepare a single record storage\n",
    "                record = np.array([time])\n",
    "\n",
    "                for landmark in custom_landmarks.landmark:\n",
    "                    # Extract pose landmarks coordinates and store as array\n",
    "                    coordinates = landmark2array(landmark)[:3]\n",
    "                    record = np.concatenate(\n",
    "                        [\n",
    "                            record,\n",
    "                            coordinates\n",
    "                        ]\n",
    "                    )\n",
    "\n",
    "                # Save pose landmarks coordinates in time as DataFrame\n",
    "                data = pd.concat([data, pd.DataFrame([record], columns = column_names)], ignore_index=True)\n",
    "\n",
    "                # Draw customize landmarks on image\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    landmark_list=custom_landmarks,\n",
    "                    connections=connections,\n",
    "                )\n",
    "\n",
    "\n",
    "        elif output == 'mask':\n",
    "            image = results.segmentation_mask\n",
    "            if image is None:\n",
    "                image = fake_background\n",
    "\n",
    "\n",
    "        cv2.imshow(f'background: {background}, output: {output}', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            exit()\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
