{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "from model_builder import VanillaRNN\n",
    "from engine import train\n",
    "from data_setup import create_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare paths\n",
    "data_path = '../data/'\n",
    "processed_data_path = os.path.join(data_path, 'processed')\n",
    "\n",
    "# Read personal data from excel\n",
    "personal_data = pd.read_excel(os.path.join(data_path, 'PersonalData.xlsx'))\n",
    "\n",
    "# Read the data that is the result of the converted videos\n",
    "data = pd.read_csv(os.path.join(processed_data_path, 'AllSquats.csv'))\n",
    "\n",
    "# Merge personal and video data\n",
    "data = pd.merge(data, personal_data, on='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the maximum load that was passed\n",
    "max_load = data.loc[data['Lifted'] == 1, ['Id', 'Load']].groupby(by='Id', as_index=False).max()\n",
    "max_load = max_load.rename(columns={'Load': 'MaxLoad'})\n",
    "data = pd.merge(data, max_load, on='Id')\n",
    "\n",
    "# Calculate what percentage of the maximum load is the current load\n",
    "data['PercentageMaxLoad'] = data['Load'] / data['MaxLoad']\n",
    "\n",
    "del data['MaxLoad']\n",
    "\n",
    "\n",
    "# Get only lifted approaches\n",
    "data = data.loc[data['Lifted'] == 1]\n",
    "\n",
    "# Variables that aren't needed in the first run\n",
    "to_drop = [\n",
    "    'Id', 'Age', 'Height', 'Weight', 'PastInjuries', 'LastInjury', 'PainDuringTraining', 'SquatRecord',\n",
    "    'BenchPressRecord', 'DeadliftRecord', 'PhysicalActivities', 'SetNumber', 'Load', 'Lifted', 'Timestamp']\n",
    "\n",
    "data = data.drop(columns=to_drop)\n",
    "\n",
    "# Categorical variables that need to be one hot encoded\n",
    "to_one_hot = [\n",
    "    'ProficiencyLevel', 'EquipmentAvailability', 'TrainingProgram', 'TrainingFrequency', 'CameraPosition']\n",
    "\n",
    "dataframe = pd.get_dummies(data, columns=to_one_hot, dtype=int)\n",
    "\n",
    "# Move the PercentageMaxLoad column to the end of the dataframe\n",
    "percentage = dataframe.pop('PercentageMaxLoad')\n",
    "dataframe['PercentageMaxLoad'] = percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique file IDs\n",
    "file_ids = dataframe['FileId'].unique()\n",
    "\n",
    "# Split the files into three lists in an 8:1:1 ratio\n",
    "train_ids, ids_to_split = train_test_split(file_ids, test_size=0.2)\n",
    "\n",
    "valid_ids, test_ids = train_test_split(ids_to_split, test_size=0.5)\n",
    "\n",
    "# Put ids into dictionary\n",
    "file_ids = {\n",
    "    \"train\": train_ids,\n",
    "    \"validation\": valid_ids,\n",
    "    \"test\": test_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "batch_size = 16\n",
    "num_workers = 0\n",
    "pin_memory = False\n",
    "\n",
    "train_dataloader, valid_dataloader, test_dataloader = create_dataloaders(\n",
    "    data=dataframe,\n",
    "    file_ids=file_ids,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "\n",
    "# model\n",
    "input_size = 78\n",
    "hidden_size = 128\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dtype = torch.float64\n",
    "\n",
    "model = VanillaRNN(\n",
    "    input_size=78,\n",
    "    hidden_size=128,\n",
    "    device=device,\n",
    "    dtype=dtype\n",
    ").to(device)\n",
    "\n",
    "# optimizer, loss function\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:06<00:57,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train loss: 0.0897 | validation loss: 0.0514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:10<00:42,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train loss: 0.0571 | validation loss: 0.0480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:15<00:34,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train loss: 0.0543 | validation loss: 0.0446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:19<00:28,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train loss: 0.0528 | validation loss: 0.0421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:24<00:23,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train loss: 0.0476 | validation loss: 0.0404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:28<00:18,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | train loss: 0.0536 | validation loss: 0.0466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:34<00:14,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | train loss: 0.0482 | validation loss: 0.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:38<00:09,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | train loss: 0.0476 | validation loss: 0.0394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:44<00:04,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | train loss: 0.0446 | validation loss: 0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:49<00:00,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | train loss: 0.0479 | validation loss: 0.0378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "results = train(model, train_dataloader, valid_dataloader, optimizer, loss_fn, n_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
