{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nemet\\DeepLearning\\sc_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mediapipe import solutions\n",
    "\n",
    "from utils import smooth_data\n",
    "from video_converter import Video2DataFrame\n",
    "from custom_pose_landmarks import CustomPoseLandmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare paths\n",
    "data_path = '../data/'\n",
    "video_path = os.path.join(data_path, 'raw/squat')\n",
    "\n",
    "# Read personal data from excel\n",
    "personal_data = pd.read_excel(os.path.join(data_path, 'PersonalData.xlsx'))\n",
    "\n",
    "# Processed data path\n",
    "processed_data = os.path.join(data_path, 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected values of pose landmarks corresponding to PoseLandmark class from MediaPipe library\n",
    "values = [0, 11, 12, 13, 14, 15, 16, 19, 20, 23, 24, 25, 26, 27, 28, 31, 32]\n",
    "\n",
    "# Custom pose landmark names and their connections\n",
    "landmarks = {\n",
    "    'THORAX': ['NOSE'],\n",
    "    'PELVIS': ['LEFT_HIP', 'RIGHT_HIP'],}\n",
    "\n",
    "# MediaPipe solutions\n",
    "mp_drawing = solutions.drawing_utils\n",
    "mp_pose = solutions.pose\n",
    "\n",
    "custom_pose = CustomPoseLandmark(mp_pose, values, landmarks)\n",
    "conv = Video2DataFrame(mp_pose, mp_drawing, custom_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 001_01_05_01_040_1_C file to dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nemet\\DeepLearning\\StrengthCoach\\notebooks\\video_converter.py:188: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat(\n"
     ]
    }
   ],
   "source": [
    "converter = Video2DataFrame(mp_pose, mp_drawing, custom_pose)\n",
    "\n",
    "# Convert videos to dataframe\n",
    "dataframe = converter.get_dataframe(\n",
    "    source=video_path,\n",
    "    detection=0.9,\n",
    "    tracking=0.9,\n",
    "    video_display=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe\n",
    "# dataframe.to_csv('ConvertedSquats.csv', index=False)\n",
    "\n",
    "# Load dataframe\n",
    "dataframe = pd.read_csv(os.path.join(processed_data, 'ConvertedSquats.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canonical form code\n",
    "default_hip_width = 1\n",
    "default_pelvis = np.zeros(shape=(3,))\n",
    "\n",
    "transformed_data = pd.DataFrame()\n",
    "\n",
    "for _, file_data in dataframe.groupby(by='FileId'):\n",
    "    # Extract starting pose coordinates\n",
    "    starting_pose = file_data.iloc[0]\n",
    "\n",
    "    # Z-axis normalization procedure\n",
    "    left_hip = starting_pose.filter(regex='LeftHip').to_numpy()\n",
    "    right_hip = starting_pose.filter(regex='RightHip').to_numpy()\n",
    "\n",
    "    left_knee = starting_pose.filter(regex='LeftKnee').to_numpy()\n",
    "    right_knee = starting_pose.filter(regex='RightKnee').to_numpy()\n",
    "\n",
    "    left_thigh_length = np.linalg.norm(left_hip - left_knee)\n",
    "    right_thigh_length = np.linalg.norm(right_hip - right_knee)\n",
    "\n",
    "    mean_length = np.mean([left_thigh_length, right_thigh_length])\n",
    "\n",
    "    # Normalization\n",
    "    to_normalize = file_data.filter(regex='Z$')\n",
    "    # min_z = to_normalize.min()\n",
    "    # max_z = to_normalize.max()\n",
    "\n",
    "    # normalized = 2 * mean_length * (to_normalize - min_z) / (max_z - min_z) - mean_length\n",
    "    normalized = mean_length * to_normalize\n",
    "\n",
    "    file_data = file_data.assign(**normalized)\n",
    "\n",
    "\n",
    "    # Extract starting pose coordinates\n",
    "    starting_pose = file_data.iloc[0]\n",
    "    \n",
    "    # Translation procedure\n",
    "    pelvis = starting_pose.filter(regex='Pelvis').to_numpy()\n",
    "\n",
    "    translation_vector = default_pelvis - pelvis\n",
    "\n",
    "    # Scaling procedure\n",
    "    left_hip = starting_pose.filter(regex='LeftHip').to_numpy()\n",
    "    right_hip = starting_pose.filter(regex='RightHip').to_numpy()\n",
    "\n",
    "    hip_vector = left_hip - right_hip\n",
    "    hip_width = np.linalg.norm(hip_vector)\n",
    "\n",
    "    scale_factor = default_hip_width / hip_width\n",
    "\n",
    "    # Transformation\n",
    "    to_transform = file_data.filter(regex='X$|Y$|Z$')\n",
    "\n",
    "    transformed = scale_factor * (\n",
    "        to_transform + np.tile(translation_vector, len(to_transform.columns) // 3)\n",
    "    )\n",
    "\n",
    "    file_data = file_data.assign(**transformed)\n",
    "    transformed_data = pd.concat([transformed_data, file_data])\n",
    "\n",
    "dataframe = transformed_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge personal and video data\n",
    "data = pd.merge(dataframe, personal_data, on='Id')\n",
    "\n",
    "# Calculate the maximum load that was passed\n",
    "max_load = data.loc[data['Lifted'] == 1, ['Id', 'Load']].groupby(by='Id', as_index=False).max()\n",
    "max_load = max_load.rename(columns={'Load': 'MaxLoad'})\n",
    "data = pd.merge(data, max_load, on='Id')\n",
    "\n",
    "# Calculate what percentage of the maximum load is the current load\n",
    "data['PercentageMaxLoad'] = 100 * data['Load'] / data['MaxLoad']\n",
    "\n",
    "del data['MaxLoad']\n",
    "\n",
    "# Get only lifted approaches\n",
    "data = data.loc[data['Lifted'] == 1]\n",
    "\n",
    "# Variables that aren't needed in the first run\n",
    "to_drop = [\n",
    "    'Id', 'Age', 'Height', 'Weight', 'PastInjuries', 'LastInjury', 'PainDuringTraining', 'SquatRecord',\n",
    "    'BenchPressRecord', 'DeadliftRecord', 'PhysicalActivities', 'SetNumber', 'Load', 'Lifted', 'Timestamp']\n",
    "\n",
    "data = data.drop(columns=to_drop)\n",
    "\n",
    "# Categorical variables that need to be one hot encoded\n",
    "to_one_hot = [\n",
    "    'ProficiencyLevel', 'EquipmentAvailability', 'TrainingProgram', 'TrainingFrequency', 'CameraPosition']\n",
    "\n",
    "data = pd.get_dummies(data, columns=to_one_hot, dtype=int)\n",
    "\n",
    "# Move the PercentageMaxLoad column to the end of the dataframe\n",
    "percentage = data.pop('PercentageMaxLoad')\n",
    "data['PercentageMaxLoad'] = percentage\n",
    "\n",
    "# Smooth all features extracted from MediaPipe solution\n",
    "data = smooth_data(data, frac=0.1, it=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe\n",
    "# data.to_csv(os.path.join(processed_data, 'OneRepMaxData_250324.csv'), index=False)\n",
    "\n",
    "# Load dataframe\n",
    "data = pd.read_csv(os.path.join(processed_data, 'OneRepMaxData_240324.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
